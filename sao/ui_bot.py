import streamlit as st
import requests
from PIL import Image

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½èŠå¤©åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "history" not in st.session_state:
    st.session_state.history = []

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    sys_prompt = st.text_input("ç³»ç»Ÿæç¤ºè¯", value="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å°åŠ©æ‰‹")
    temperature = st.slider("æ¸©åº¦", min_value=0.1, max_value=2.0, step=0.1, value=0.7)
    top_p = st.slider("é‡‡æ ·ç‡", min_value=0.0, max_value=1.0, step=0.1, value=0.5)
    max_tokens = st.slider("æœ€å¤§åˆ†è¯é‡", min_value=100, max_value=2048, step=100, value=1024)
    history_len = st.slider("ä¿ç•™å†å²èŠå¤©é•¿åº¦", min_value=2, max_value=20, step=1, value=5)
    model = st.radio("é€‰æ‹©æ¨¡å‹", ("deepseek-ai/DeepSeek-R1-0528-Qwen3-8B", "Qwen/Qwen3-8B", "THUDM/GLM-Z1-9B-0414"))
    stream = st.checkbox("æµå¼è¾“å‡º", value=True)

    # æ¸…ç©ºèŠå¤©è®°å½•
    if st.button("æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.history = []
        st.success("èŠå¤©è®°å½•å·²æ¸…ç©º")

# æ˜¾ç¤ºå†å²èŠå¤©
for message in st.session_state.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# è¾“å…¥æ¡†
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)

    # å‡†å¤‡è¯·æ±‚æ•°æ®
    data = {
        "query": prompt,
        "sys_prompt": sys_prompt,
        "temperature": temperature,
        "top_p": top_p,
        "max_tokens": max_tokens,
        "history_len": history_len,
        "history": st.session_state.history,
        "model": model,
    }

    backend_url = "http://127.0.0.1:1234/chat"

    # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ¥æ˜¾ç¤ºåŠ©æ‰‹çš„å›å¤
    assistant_placeholder = st.chat_message("assistant")
    assistant_text = assistant_placeholder.markdown("æ­£åœ¨å“åº”ä¸­ï¼Œè¯·ç¨ç­‰...")

    try:
        # å‘é€è¯·æ±‚åˆ°åç«¯
        response = requests.post(backend_url, json=data, stream=True)

        if response.status_code == 200:
            full_response = ""

            # å¤„ç†æµå¼å“åº”
            if stream:
                for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
                    if chunk:
                        full_response += chunk
                        assistant_text.markdown(full_response)
            else:
                # è·å–å®Œæ•´å“åº”
                full_response = response.text
                assistant_text.markdown(full_response)

            # æ›´æ–°å†å²è®°å½•
            st.session_state.history.append({"role": "user", "content": prompt})
            st.session_state.history.append({"role": "assistant", "content": full_response})
        else:
            assistant_text.markdown(f"é”™è¯¯: æœåŠ¡å™¨è¿”å›çŠ¶æ€ç  {response.status_code}")
    except Exception as e:
        assistant_text.markdown(f"é”™è¯¯: {str(e)}")
